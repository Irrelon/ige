"use strict";
/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(self["webpackChunk_irrelon_ige"] = self["webpackChunk_irrelon_ige"] || []).push([["src_examples_webGpuRenderer_client_ts"],{

/***/ "./src/engine/core/IgeAsset.ts":
/*!*************************************!*\
  !*** ./src/engine/core/IgeAsset.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   IgeAsset: () => (/* binding */ IgeAsset)\n/* harmony export */ });\n/* harmony import */ var _engine_core_IgeEventingClass__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @/engine/core/IgeEventingClass */ \"./src/engine/core/IgeEventingClass.ts\");\n\nclass IgeAsset extends _engine_core_IgeEventingClass__WEBPACK_IMPORTED_MODULE_0__.IgeEventingClass {\n    constructor() {\n        super(...arguments);\n        this._loaded = false;\n    }\n    id(id) {\n        if (id === undefined)\n            return this._assetId;\n        this._assetId = id;\n    }\n    /**\n     * A promise that resolves to true when the asset has loaded.\n     */\n    whenLoaded() {\n        return new Promise((resolve) => {\n            if (this._loaded) {\n                return resolve(true);\n            }\n            const listener = () => {\n                resolve(true);\n                this.off(\"loaded\", listener);\n            };\n            this.on(\"loaded\", listener);\n        });\n    }\n    _assetLoaded() {\n        // Set a timeout here so that when this event is emitted,\n        // the code creating the asset is given a chance to\n        // set a listener first, otherwise this will be emitted\n        // but nothing will have time to register a listener!\n        setTimeout(() => {\n            this._loaded = true;\n            this.emit(\"loaded\");\n        }, 5);\n    }\n    destroy() {\n        return this;\n    }\n}\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/core/IgeAsset.ts?");

/***/ }),

/***/ "./src/engine/core/IgeBaseRenderer.ts":
/*!********************************************!*\
  !*** ./src/engine/core/IgeBaseRenderer.ts ***!
  \********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   IgeBaseRenderer: () => (/* binding */ IgeBaseRenderer)\n/* harmony export */ });\n/* harmony import */ var _engine_core_IgeEventingClass__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @/engine/core/IgeEventingClass */ \"./src/engine/core/IgeEventingClass.ts\");\n/* harmony import */ var _engine_core_IgePoint2d__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @/engine/core/IgePoint2d */ \"./src/engine/core/IgePoint2d.ts\");\n/* harmony import */ var _engine_instance__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @/engine/instance */ \"./src/engine/instance.ts\");\n/* harmony import */ var _engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @/engine/utils/clientServer */ \"./src/engine/utils/clientServer.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\nclass IgeBaseRenderer extends _engine_core_IgeEventingClass__WEBPACK_IMPORTED_MODULE_0__.IgeEventingClass {\n    constructor() {\n        super();\n        this.classId = \"IgeBaseRenderer\";\n        this._hasRunSetup = false;\n        this._isReady = false;\n        this._bounds2d = new _engine_core_IgePoint2d__WEBPACK_IMPORTED_MODULE_1__.IgePoint2d(800, 600);\n        this._createdFrontBuffer = false;\n        this._pixelRatioScaling = true;\n        this._devicePixelRatio = 1;\n        this._autoSize = true;\n        this._resized = false;\n        this._resizeEvent = (event) => {\n        };\n        /**\n         * Toggles full-screen output of the renderer canvas. Only works\n         * if called from within a user-generated HTML event listener.\n         */\n        this.toggleFullScreen = () => {\n        };\n    }\n    setup() {\n        return __awaiter(this, void 0, void 0, function* () {\n            // Don't run setup on server, we don't render on the server,\n            // so we don't need a canvas or rendering backend!\n            if (_engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_3__.isServer)\n                return;\n            // Check if we've already run setup before\n            if (this._hasRunSetup)\n                return;\n            // Now call the _setup() method which gets called\n            // on the extending class, so we can control the order\n            // that code executes rather than the extending class\n            // overriding the setup() method\n            yield this._setup();\n            _engine_instance__WEBPACK_IMPORTED_MODULE_2__.ige.engine.headless(false);\n            this.isReady(true);\n            this.log(\"Setup executed\");\n        });\n    }\n    /**\n     * Implement this setup function in the renderer that extends\n     * this base class. Called once by the engine via the setup() function\n     * when the renderer is first added. Will not run server-side.\n     */\n    _setup() {\n        return __awaiter(this, void 0, void 0, function* () {\n        });\n    }\n    isReady(val) {\n        if (val === undefined) {\n            return this._isReady;\n        }\n        this._isReady = val;\n        return this;\n    }\n    destroy() {\n        this._removeEventListeners();\n    }\n    canvasElement(elem, autoSize = true) {\n        return this._canvasElement;\n    }\n    _addEventListeners() {\n        //window.addEventListener(\"resize\", this._resizeEvent);\n    }\n    _removeEventListeners() {\n        //window.removeEventListener(\"resize\", this._resizeEvent);\n    }\n    renderSceneGraph(engine, viewports) {\n        return this._renderSceneGraph(engine, viewports);\n    }\n    _renderSceneGraph(engine, viewports) {\n        return false;\n    }\n    _updateDevicePixelRatio() {\n        if (!this._canvasElement)\n            return;\n        if (_engine_instance__WEBPACK_IMPORTED_MODULE_2__.ige.engine._pixelRatioScaling) {\n            // Support high-definition devices and \"retina\" displays by adjusting\n            // for device and back store pixels ratios\n            this._devicePixelRatio = window.devicePixelRatio || 1;\n        }\n        else {\n            // No auto-scaling\n            this._devicePixelRatio = 1;\n        }\n        if (this._devicePixelRatio !== 1) {\n            this._canvasElement.style.width = this._bounds2d.x + \"px\";\n            this._canvasElement.style.height = this._bounds2d.y + \"px\";\n        }\n        //this.log(`Device pixel ratio is ${this._devicePixelRatio}`);\n    }\n}\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/core/IgeBaseRenderer.ts?");

/***/ }),

/***/ "./src/engine/core/IgeBaseScene.ts":
/*!*****************************************!*\
  !*** ./src/engine/core/IgeBaseScene.ts ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   IgeBaseScene: () => (/* binding */ IgeBaseScene)\n/* harmony export */ });\n/* harmony import */ var _engine_core_IgeScene2d__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @/engine/core/IgeScene2d */ \"./src/engine/core/IgeScene2d.ts\");\n/* harmony import */ var _engine_core_IgeSceneGraph__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @/engine/core/IgeSceneGraph */ \"./src/engine/core/IgeSceneGraph.ts\");\n/* harmony import */ var _engine_core_IgeViewport__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @/engine/core/IgeViewport */ \"./src/engine/core/IgeViewport.ts\");\n/* harmony import */ var _engine_instance__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @/engine/instance */ \"./src/engine/instance.ts\");\n/* harmony import */ var _engine_utils_igeClassStore__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @/engine/utils/igeClassStore */ \"./src/engine/utils/igeClassStore.ts\");\n\n\n\n\n\n/**\n * When loaded into memory using ige.addGraph('IgeBaseScene') will create\n * the scene \"baseScene\" and the viewport \"vp1\" that are used in almost all\n * examples and can be used as the base for your scenegraph as well.\n */\nclass IgeBaseScene extends _engine_core_IgeSceneGraph__WEBPACK_IMPORTED_MODULE_1__.IgeSceneGraph {\n    constructor() {\n        super(...arguments);\n        this.classId = \"IgeBaseScene\";\n        /**\n         * Called when loading the graph data via ige.addGraph().\n         */\n        this.addGraph = () => {\n            // Clear existing graph data\n            if (_engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.$(\"baseScene\")) {\n                this.removeGraph();\n            }\n            // Create the scene\n            const baseScene = new _engine_core_IgeScene2d__WEBPACK_IMPORTED_MODULE_0__.IgeScene2d().id(\"baseScene\");\n            // Create the main viewport to look at \"baseScene\"\n            new _engine_core_IgeViewport__WEBPACK_IMPORTED_MODULE_2__.IgeViewport()\n                .id(\"vp1\")\n                .autoSize(true)\n                .scene(baseScene)\n                .drawBounds(false)\n                .drawBoundsData(false)\n                .mount(_engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.engine);\n        };\n        /**\n         * The method called when the graph items are to be removed from the\n         * active graph.\n         */\n        this.removeGraph = () => {\n            var _a, _b;\n            // Destroy the viewport\n            (_a = _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.$(\"vp1\")) === null || _a === void 0 ? void 0 : _a.destroy();\n            // Destroy the baseScene\n            (_b = _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.$(\"baseScene\")) === null || _b === void 0 ? void 0 : _b.destroy();\n        };\n    }\n}\n(0,_engine_utils_igeClassStore__WEBPACK_IMPORTED_MODULE_4__.registerClass)(IgeBaseScene);\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/core/IgeBaseScene.ts?");

/***/ }),

/***/ "./src/engine/core/IgeCanvas.ts":
/*!**************************************!*\
  !*** ./src/engine/core/IgeCanvas.ts ***!
  \**************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   newCanvas: () => (/* binding */ newCanvas)\n/* harmony export */ });\nconst newCanvas = () => {\n    const instance = new OffscreenCanvas(2, 2);\n    Object.defineProperty(instance, \"_igeTextures\", {\n        configurable: true,\n        enumerable: true,\n        writable: true,\n        value: []\n    });\n    Object.defineProperty(instance, \"_loaded\", {\n        configurable: true,\n        enumerable: true,\n        writable: true,\n        value: false\n    });\n    Object.defineProperty(instance, \"src\", {\n        configurable: true,\n        enumerable: true,\n        writable: true,\n        value: \"Canvas\"\n    });\n    return instance;\n};\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/core/IgeCanvas.ts?");

/***/ }),

/***/ "./src/engine/core/IgeScene2d.ts":
/*!***************************************!*\
  !*** ./src/engine/core/IgeScene2d.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   IgeScene2d: () => (/* binding */ IgeScene2d)\n/* harmony export */ });\n/* harmony import */ var _engine_core_IgeEntity__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @/engine/core/IgeEntity */ \"./src/engine/core/IgeEntity.ts\");\n/* harmony import */ var _engine_instance__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @/engine/instance */ \"./src/engine/instance.ts\");\n/* harmony import */ var _engine_utils_igeClassStore__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @/engine/utils/igeClassStore */ \"./src/engine/utils/igeClassStore.ts\");\n\n\n\n/**\n * Creates a new 2d scene.\n */\nclass IgeScene2d extends _engine_core_IgeEntity__WEBPACK_IMPORTED_MODULE_0__.IgeEntity {\n    constructor() {\n        super();\n        this.classId = \"IgeScene2d\";\n        /**\n         * Gets / sets the stream room id. If set, any streaming entities that\n         * are mounted to this scene will only sync with clients that have been\n         * assigned to this room id.\n         *\n         * @param {string} id The id of the room.\n         * @returns {*}\n         */\n        this.streamRoomId = (id) => {\n            if (id !== undefined) {\n                this._streamRoomId = id;\n                return this;\n            }\n            return this._streamRoomId;\n        };\n        /**\n         * Overrides the default entity stream sections to also stream important\n         * data about scenes to the client.\n         * @param sectionId\n         * @param data\n         * @returns {*}\n         */\n        this.streamSectionData = (sectionId, data) => {\n            switch (sectionId) {\n                case \"ignoreCamera\":\n                    if (data !== undefined) {\n                        // Setter\n                        if (data === \"false\") {\n                            this.ignoreCamera(false);\n                        }\n                        else {\n                            this.ignoreCamera(true);\n                        }\n                    }\n                    else {\n                        // Getter\n                        return String(this._ignoreCamera);\n                    }\n                    break;\n                default:\n                    super.streamSectionData(sectionId, data);\n                    break;\n            }\n        };\n        /**\n         * Gets / sets the auto-size property. If set to true, the scene will\n         * automatically resize to the engine's canvas geometry.\n         * @param {Boolean=} val If true, will autosize the scene to match the\n         * main canvas geometry. This is enabled by default and is unlikely to\n         * help you if you switch it off.\n         * @return {*}\n         */\n        this.autoSize = (val) => {\n            if (typeof val !== \"undefined\") {\n                this._autoSize = val;\n                return this;\n            }\n            return this._autoSize;\n        };\n        /**\n         * Gets / sets the _shouldRender property. If set to true, the scene's child\n         * object's tick methods will be called.\n         * @param {Boolean} val If set to false, no child entities will be rendered.\n         * @return {Boolean}\n         */\n        this.shouldRender = (val) => {\n            if (val !== undefined) {\n                this._shouldRender = val;\n                return this;\n            }\n            return this._shouldRender;\n        };\n        this.update = (tickDelta) => {\n            if (this._ignoreCamera) {\n                // Translate the scene, so it is always center of the camera\n                const cam = _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._currentCamera;\n                if (cam) {\n                    this.translateTo(cam._translate.x, cam._translate.y, cam._translate.z);\n                    this.scaleTo(1 / cam._scale.x, 1 / cam._scale.y, 1 / cam._scale.z);\n                    this.rotateTo(-cam._rotate.x, -cam._rotate.y, -cam._rotate.z);\n                    //this._localMatrix.multiply(ige._currentCamera._worldMatrix.getInverse());\n                }\n            }\n            super.update(tickDelta);\n        };\n        /**\n         * Handles screen resize events.\n         * @param event\n         * @private\n         */\n        this._resizeEvent = (event) => {\n            // Set width / height of scene to match main ige (SCENES ARE ALWAYS THE FULL IGE SIZE!!)\n            if (this._autoSize && _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine) {\n                this._bounds2d = _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._bounds2d.clone();\n            }\n            // Resize any children\n            const arr = this._children;\n            let arrCount = arr.length;\n            while (arrCount--) {\n                arr[arrCount]._resizeEvent(event);\n            }\n        };\n        this._pointerAlwaysInside = true;\n        this._alwaysInView = true;\n        this._shouldRender = true;\n        this._autoSize = true;\n        // Set the geometry of the scene to the main canvas\n        // width / height - used when positioning UI elements\n        this._bounds2d.x = _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._bounds2d.x;\n        this._bounds2d.y = _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._bounds2d.y;\n        this.streamSections([\"transform\", \"ignoreCamera\"]);\n    }\n    ignoreCamera(val) {\n        if (val !== undefined) {\n            this._ignoreCamera = val;\n            return this;\n        }\n        return this._ignoreCamera;\n    }\n    /**\n     * Processes the actions required each render frame.\n     * @param {CanvasRenderingContext2D} ctx The canvas context to render to.\n     */\n    tick(ctx) {\n        if (this._shouldRender) {\n            super.tick(ctx);\n        }\n    }\n    /**\n     * Returns a string containing a code fragment that when\n     * evaluated will reproduce this object's properties via\n     * chained commands. This method will only check for\n     * properties that are directly related to this class.\n     * Other properties are handled by their own class method.\n     * @return {String}\n     */\n    _stringify() {\n        // Get the properties for all the super-classes\n        let str = super._stringify(), i;\n        // Loop properties and add property assignment code to string\n        for (i in this) {\n            // @ts-ignore\n            if (this.hasOwnProperty(i) && this[i] !== undefined) {\n                switch (i) {\n                    case \"_shouldRender\":\n                        str += \".shouldRender(\" + this.shouldRender() + \")\";\n                        break;\n                    case \"_autoSize\":\n                        str += \".autoSize(\" + this.autoSize() + \")\";\n                        break;\n                }\n            }\n        }\n        return str;\n    }\n}\n(0,_engine_utils_igeClassStore__WEBPACK_IMPORTED_MODULE_2__.registerClass)(IgeScene2d);\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/core/IgeScene2d.ts?");

/***/ }),

/***/ "./src/engine/core/IgeSceneGraph.ts":
/*!******************************************!*\
  !*** ./src/engine/core/IgeSceneGraph.ts ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   IgeSceneGraph: () => (/* binding */ IgeSceneGraph)\n/* harmony export */ });\n/* harmony import */ var _engine_core_IgeBaseClass__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @/engine/core/IgeBaseClass */ \"./src/engine/core/IgeBaseClass.ts\");\n\nclass IgeSceneGraph extends _engine_core_IgeBaseClass__WEBPACK_IMPORTED_MODULE_0__.IgeBaseClass {\n    constructor() {\n        super(...arguments);\n        this.classId = \"IgeSceneGraph\";\n    }\n    /**\n     * Called when loading the graph data via ige.addGraph().\n     * @param {Object=} options The options that were passed with the call\n     * to ige.addGraph().\n     */\n    addGraph(options) {\n    }\n    /**\n     * The method called when the graph items are to be removed from the\n     * active graph.\n     */\n    removeGraph(options) {\n    }\n}\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/core/IgeSceneGraph.ts?");

/***/ }),

/***/ "./src/engine/core/IgeTexture.ts":
/*!***************************************!*\
  !*** ./src/engine/core/IgeTexture.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   IgeTexture: () => (/* binding */ IgeTexture)\n/* harmony export */ });\n/* harmony import */ var _engine_core_IgeAsset__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @/engine/core/IgeAsset */ \"./src/engine/core/IgeAsset.ts\");\n/* harmony import */ var _engine_core_IgeCanvas__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @/engine/core/IgeCanvas */ \"./src/engine/core/IgeCanvas.ts\");\n/* harmony import */ var _engine_core_IgeDependencies__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @/engine/core/IgeDependencies */ \"./src/engine/core/IgeDependencies.ts\");\n/* harmony import */ var _engine_instance__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @/engine/instance */ \"./src/engine/instance.ts\");\n/* harmony import */ var _engine_utils_arrays__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @/engine/utils/arrays */ \"./src/engine/utils/arrays.ts\");\n/* harmony import */ var _engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @/engine/utils/clientServer */ \"./src/engine/utils/clientServer.ts\");\n/* harmony import */ var _enums__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @/enums */ \"./src/enums/index.ts\");\n\n\n\n\n\n\n\n/**\n * Creates a new texture.\n */\nclass IgeTexture extends _engine_core_IgeAsset__WEBPACK_IMPORTED_MODULE_0__.IgeAsset {\n    /**\n     * Constructor for a new IgeTexture.\n     * @param id\n     * @param {string | IgeSmartTexture} urlOrObject Either a string URL that\n     * points to the path of the image or script you wish to use as\n     * the texture image, or an object containing a smart texture.\n     */\n    constructor(id, urlOrObject) {\n        super();\n        this.classId = \"IgeTexture\";\n        this.IgeTexture = true;\n        this._noDimensions = false;\n        this._sizeX = 0;\n        this._sizeY = 0;\n        this._renderMode = _enums__WEBPACK_IMPORTED_MODULE_6__.IgeTextureRenderMode.none;\n        this._smoothing = false;\n        this._filterImageDrawn = false;\n        this._destroyed = false;\n        this._applyFilters = []; // TODO: Rename to _postFilters\n        this._applyFiltersData = [];\n        this._preFilters = [];\n        this._preFiltersData = [];\n        this._cells = []; // The fist index of this array is 1 for some reason\n        this.dependencies = new _engine_core_IgeDependencies__WEBPACK_IMPORTED_MODULE_2__.IgeDependencies();\n        /**\n         * Loads a render script into a script tag and sets an onload\n         * event to capture when the script has finished loading.\n         * @param {string} scriptUrl The script url used to load the\n         * script data.\n         * @private\n         */\n        this._loadScript = (scriptUrl) => {\n            if (!_engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_5__.isClient) {\n                return;\n            }\n            import(/*webpackIgnore: true*/ scriptUrl)\n                .then(({ image }) => {\n                this.log(`Texture script \"${scriptUrl}\" loaded successfully`);\n                // Store the function exported in the `image` variable\n                // by the texture script\n                this._renderMode = _enums__WEBPACK_IMPORTED_MODULE_6__.IgeTextureRenderMode.smartTexture;\n                this.script = image;\n                // Run the asset script init method\n                if (typeof image.init === \"function\") {\n                    image.init.apply(image, [this]);\n                }\n                // Mark texture as loaded\n                this._assetLoaded();\n            })\n                .catch((err) => {\n                this.log(`Module error ${err}`, \"error\");\n            });\n        };\n        this._loaded = false;\n        if (_engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_5__.isServer) {\n            this.log(`Cannot create a texture on the server. Textures are only client-side objects. Please alter your code so that you don't try to load a texture on the server-side, using something like an if statement around your texture loading such as \"if (isClient) {...}\".`, \"error\");\n            return this;\n        }\n        if (id) {\n            const alreadyExists = _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.textures.exists(id);\n            if (alreadyExists) {\n                return _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.textures.get(id);\n            }\n            this.id(id);\n            _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.textures.add(id, this);\n        }\n        // Create an array that is used to store cell dimensions\n        this._cells = [];\n        this._smoothing = _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.engine._globalSmoothing;\n        // Instantiate filter lists for filter combinations\n        this._applyFilters = [];\n        this._applyFiltersData = [];\n        this._preFilters = [];\n        this._preFiltersData = [];\n        if (!urlOrObject)\n            return;\n        if (typeof urlOrObject === \"string\") {\n            // Load the texture URL\n            if (urlOrObject) {\n                this.url(urlOrObject);\n            }\n        }\n        else {\n            // Assign the texture script object\n            this.assignSmartTextureImage(urlOrObject);\n        }\n    }\n    url(url) {\n        if (url !== undefined) {\n            this._url = url;\n            if (url.substr(url.length - 3, 3) === \".js\") {\n                // This is a script-based texture, load the script\n                this._loadScript(url);\n            }\n            else {\n                // This is an image-based texture, load the image\n                this._loadImage(url);\n            }\n            return this;\n        }\n        return this._url;\n    }\n    /**\n     * Loads an image into an img tag and sets an onload event\n     * to capture when the image has finished loading.\n     * @param {string} imageUrl The image url used to load the\n     * image data.\n     * @private\n     */\n    _loadImage(imageUrl) {\n        if (!_engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_5__.isClient) {\n            return false;\n        }\n        if (!_engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.textures._textureImageStore[imageUrl]) {\n            fetch(imageUrl)\n                .then((resp) => resp.blob())\n                .then((blob) => createImageBitmap(blob))\n                .then((image) => {\n                _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.textures._textureImageStore[imageUrl] = this.image = this._originalImage = image;\n                image._igeTextures = image._igeTextures || [];\n                // Add this texture to the textures that are using this image\n                image._igeTextures.push(this);\n                // Mark the image as loaded\n                image._loaded = true;\n                // Log success\n                this.log(\"Texture image (\" + imageUrl + \") loaded successfully\");\n                /*if (image.width % 2) {\n                        self.log('The texture ' + imageUrl + ' width (' + image.width + ') is not divisible by 2 to a whole number! This can cause rendering artifacts. It can also cause performance issues on some GPUs. Please make sure your texture width is divisible by 2!', 'warning');\n                    }\n\n                    if (image.height % 2) {\n                        self.log('The texture ' + imageUrl + ' height (' + image.height + ') is not divisible by 2 to a whole number! This can cause rendering artifacts. It can also cause performance issues on some GPUs. Please make sure your texture height is divisible by 2!', 'warning');\n                    }*/\n                // Loop textures that are using this image\n                const arr = image._igeTextures;\n                const arrCount = arr.length;\n                for (let i = 0; i < arrCount; i++) {\n                    const item = arr[i];\n                    item._renderMode = _enums__WEBPACK_IMPORTED_MODULE_6__.IgeTextureRenderMode.image;\n                    item.sizeX(image.width);\n                    item.sizeY(image.height);\n                    item._cells[1] = [0, 0, item._sizeX, item._sizeY];\n                }\n                // Mark texture as loaded\n                this._assetLoaded();\n            });\n        }\n        else {\n            // Grab the cached image object\n            const image = (this.image = this._originalImage = _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.textures._textureImageStore[imageUrl]);\n            // Add this texture to the textures that are using this image\n            image._igeTextures.push(this);\n            if (image._loaded) {\n                // The cached image object is already loaded so\n                // fire off the relevant events\n                this._renderMode = _enums__WEBPACK_IMPORTED_MODULE_6__.IgeTextureRenderMode.image;\n                this.sizeX(image.width);\n                this.sizeY(image.height);\n                if (image.width % 2) {\n                    this.log(\"This texture's width is not divisible by 2 which will cause the texture to use sub-pixel rendering resulting in a blurred image. This may also slow down the renderer on some browsers. Image file: \" +\n                        this._url, \"warning\");\n                }\n                if (image.height % 2) {\n                    this.log(\"This texture's height is not divisible by 2 which will cause the texture to use sub-pixel rendering resulting in a blurred image. This may also slow down the renderer on some browsers. Image file: \" +\n                        this._url, \"warning\");\n                }\n                this._cells[1] = [0, 0, this._sizeX, this._sizeY];\n                // Mark texture as loaded\n                this._assetLoaded();\n            }\n        }\n    }\n    /**\n     * Assigns a render script to the smart texture.\n     * @param {string} scriptObj The script object.\n     * @private\n     */\n    assignSmartTextureImage(scriptObj) {\n        // Check the object has a render method\n        if (typeof scriptObj.render !== \"function\") {\n            throw new Error(\"Cannot assign smart texture because it doesn't have a render() method!\");\n        }\n        // Store the script data\n        this._renderMode = _enums__WEBPACK_IMPORTED_MODULE_6__.IgeTextureRenderMode.smartTexture;\n        this.script = scriptObj;\n        // Run the asset script init method\n        if (typeof scriptObj.init === \"function\") {\n            scriptObj.init.apply(scriptObj, [this]);\n        }\n        this._loaded = true;\n        this.emit(\"loaded\");\n    }\n    /**\n     * Sets the image element that the IgeTexture will use when\n     * rendering. This is a special method not designed to be called\n     * directly by any game code and is used specifically when\n     * assigning an existing canvas element to an IgeTexture.\n     * @param {IgeImage} imageElement The canvas / image to use as\n     * the image data for the IgeTexture.\n     * @private\n     */\n    _setImage(imageElement) {\n        if (_engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_5__.isClient) {\n            // Create the image object\n            const image = (this.image = this._originalImage = imageElement);\n            // Mark the image as loaded\n            image._loaded = true;\n            this._renderMode = _enums__WEBPACK_IMPORTED_MODULE_6__.IgeTextureRenderMode.image;\n            this.sizeX(image.width);\n            this.sizeY(image.height);\n            this._cells[1] = [0, 0, this._sizeX, this._sizeY];\n        }\n    }\n    /**\n     * Sets the _sizeX property.\n     * @param {number} val\n     */\n    sizeX(val) {\n        this._sizeX = val;\n    }\n    /**\n     * Sets the _sizeY property.\n     * @param {number} val\n     */\n    sizeY(val) {\n        this._sizeY = val;\n    }\n    /**\n     * Resizes the original texture image to a new size. This alters\n     * the image that the texture renders so all entities that use\n     * this texture will output the newly resized version of the image.\n     * @param {number} x The new width.\n     * @param {number} y The new height.\n     * @param {boolean=} dontDraw If true the resized image will not be\n     * drawn to the texture canvas. Useful for just resizing the texture\n     * canvas and not the output image. Use in conjunction with the\n     * applyFilter() and preFilter() methods.\n     */\n    resize(x, y, dontDraw = false) {\n        if (this._originalImage) {\n            if (!this._loaded) {\n                throw new Error(`Cannot resize texture because the texture image (${this._url}) has not loaded into memory yet!`);\n            }\n            if (!this._textureCtx || !this._textureCanvas) {\n                // Create a new canvas\n                this._textureCanvas = (0,_engine_core_IgeCanvas__WEBPACK_IMPORTED_MODULE_1__.newCanvas)();\n            }\n            this._textureCanvas.width = x;\n            this._textureCanvas.height = y;\n            const tmpCtx = this._textureCanvas.getContext(\"2d\");\n            if (!tmpCtx) {\n                throw new Error(\"Couldn't get texture canvas 2d context!\");\n            }\n            this._textureCtx = tmpCtx;\n            // Set smoothing mode\n            this._textureCtx.imageSmoothingEnabled = this._smoothing;\n            if (!dontDraw) {\n                // Draw the original image to the new canvas\n                // scaled as required\n                this._textureCtx.drawImage(this._originalImage, 0, 0, this._originalImage.width, this._originalImage.height, 0, 0, x, y);\n            }\n            // Swap the current image for this new canvas\n            this.image = this._textureCanvas;\n        }\n    }\n    /**\n     * Resizes the original texture image to a new size based on percentage.\n     * This alters the image that the texture renders so all entities that use\n     * this texture will output the newly resized version of the image.\n     * @param {number} x The new width.\n     * @param {number} y The new height.\n     * @param {Boolean=} dontDraw If true the resized image will not be\n     * drawn to the texture canvas. Useful for just resizing the texture\n     * canvas and not the output image. Use in conjunction with the\n     * applyFilter() and preFilter() methods.\n     */\n    resizeByPercent(x, y, dontDraw = false) {\n        if (!this._originalImage) {\n            return;\n        }\n        if (!this._loaded) {\n            throw new Error(`Cannot resize texture because the texture image (${this._url}) has not loaded into memory yet!`);\n        }\n        // Calc final x/y values\n        x = Math.floor((this._originalImage.width / 100) * x);\n        y = Math.floor((this._originalImage.height / 100) * y);\n        if (!this._textureCtx || !this._textureCanvas) {\n            // Create a new canvas\n            this._textureCanvas = (0,_engine_core_IgeCanvas__WEBPACK_IMPORTED_MODULE_1__.newCanvas)();\n        }\n        this._textureCanvas.width = x;\n        this._textureCanvas.height = y;\n        const tmpCtx = this._textureCanvas.getContext(\"2d\");\n        if (!tmpCtx) {\n            throw new Error(\"Couldn't get texture canvas 2d context!\");\n        }\n        this._textureCtx = tmpCtx;\n        // Set smoothing mode\n        this._textureCtx.imageSmoothingEnabled = this._smoothing;\n        if (!dontDraw) {\n            // Draw the original image to the new canvas\n            // scaled as required\n            this._textureCtx.drawImage(this._originalImage, 0, 0, this._originalImage.width, this._originalImage.height, 0, 0, x, y);\n        }\n        // Swap the current image for this new canvas\n        this.image = this._textureCanvas;\n    }\n    /**\n     * Sets the texture image back to the original image that the\n     * texture first loaded. Useful if you have applied filters\n     * or resized the image and now want to revert to the original.\n     */\n    restoreOriginal() {\n        this.image = this._originalImage;\n        delete this._textureCtx;\n        delete this._textureCanvas;\n        this.removeFilters();\n    }\n    smoothing(val) {\n        if (val !== undefined) {\n            this._smoothing = val;\n            return this;\n        }\n        return this._smoothing;\n    }\n    /**\n     * Renders the texture image to the passed canvas context.\n     * @param {CanvasRenderingContext2D} ctx The canvas context to draw to.\n     * @param {IgeEntity} entity The entity that this texture is\n     * being drawn for.\n     */\n    render(ctx, entity) {\n        // Check that the cell is not set to null. If it is then\n        // we don't render anything which effectively makes the\n        // entity \"blank\"\n        if (entity._cell === null) {\n            return;\n        }\n        ctx.imageSmoothingEnabled = this._smoothing;\n        if (this._renderMode === _enums__WEBPACK_IMPORTED_MODULE_6__.IgeTextureRenderMode.image) {\n            // This texture is image-based\n            if (!this._originalImage || !this.image) {\n                throw new Error(\"No image is available to render but the IgeTexture is in mode zero (image based render)!\");\n            }\n            const cell = this._cells[entity._cell];\n            const geom = entity._bounds2d;\n            const poly = entity._renderPos; // Render pos is calculated in the IgeEntity.aabb() method\n            if (!cell) {\n                throw new Error(`Cannot render texture using cell ${entity._cell} because the cell does not exist in the assigned texture!`);\n            }\n            if (this._preFilters.length > 0 && this._textureCanvas && this._textureCtx) {\n                // Call the drawing of the original image\n                this._textureCtx.clearRect(0, 0, this._textureCanvas.width, this._textureCanvas.height);\n                this._textureCtx.drawImage(this._originalImage, 0, 0);\n                // Call the applyFilter and preFilter methods one by one\n                this._applyFilters.forEach((method, index) => {\n                    if (!this._textureCanvas || !this._textureCtx || !this._originalImage)\n                        return;\n                    this._textureCtx.save();\n                    method(this._textureCanvas, this._textureCtx, this._originalImage, this, this._applyFiltersData[index]);\n                    this._textureCtx.restore();\n                });\n                this._preFilters.forEach((method, index) => {\n                    if (!this._textureCanvas || !this._textureCtx || !this._originalImage)\n                        return;\n                    this._textureCtx.save();\n                    method(this._textureCanvas, this._textureCtx, this._originalImage, this, this._preFiltersData[index]);\n                    this._textureCtx.restore();\n                });\n            }\n            ctx.drawImage(this.image, cell[0], // texture x\n            cell[1], // texture y\n            cell[2], // texture width\n            cell[3], // texture height\n            poly.x, // render x\n            poly.y, // render y\n            geom.x, // render width\n            geom.y // render height\n            );\n            _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.metrics.drawCount++;\n        }\n        if (this._renderMode === _enums__WEBPACK_IMPORTED_MODULE_6__.IgeTextureRenderMode.smartTexture) {\n            if (!this.script) {\n                throw new Error(\"No smart texture is available to render but the IgeTexture is in mode one (script based render)!\");\n            }\n            // This texture is script-based (a \"smart texture\")\n            ctx.save();\n            this.script.render(ctx, entity, this);\n            ctx.restore();\n            _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.metrics.drawCount++;\n        }\n    }\n    /**\n     * Removes a certain filter from the texture\n     * Useful if you want to keep resizings, etc.\n     */\n    removeFilter(method) {\n        // TODO: Maybe we should refactor filter data structures so that the filter data is stored alongside the filter method?\n        const matchingPreFilterIndexes = [];\n        const matchingApplyFilterIndexes = [];\n        // Find any filter methods that match the passed `method`\n        this._preFilters.forEach((tmpFilterItem, index) => {\n            if (tmpFilterItem === method) {\n                matchingPreFilterIndexes.push(index);\n            }\n        });\n        this._applyFilters.forEach((tmpFilterItem, index) => {\n            if (tmpFilterItem === method) {\n                matchingApplyFilterIndexes.push(index);\n            }\n        });\n        // Remove any filter methods that match the passed `method`\n        for (let i = matchingPreFilterIndexes.length - 1; i >= 0; i--) {\n            const index = matchingPreFilterIndexes[i];\n            this._preFilters.splice(index, 1);\n            this._preFiltersData.splice(index, 1);\n        }\n        for (let i = matchingApplyFilterIndexes.length - 1; i >= 0; i--) {\n            const index = matchingApplyFilterIndexes[i];\n            this._applyFilters.splice(index, 1);\n            this._applyFiltersData.splice(index, 1);\n        }\n        this._rerenderFilters();\n    }\n    /**\n     * Removes all filters on the texture\n     * Useful if you want to keep resizings, etc.\n     */\n    removeFilters() {\n        this._applyFilters = [];\n        this._applyFiltersData = [];\n        this._preFilters = [];\n        this._preFiltersData = [];\n        this._rerenderFilters();\n    }\n    /**\n     * Rerenders image with filter list. Keeps sizings.\n     * Useful if you have no preFilters\n     */\n    _rerenderFilters() {\n        if (!this._textureCanvas)\n            return;\n        // Rerender applyFilters from scratch:\n        // Draw the basic image\n        // resize it to the old boundaries\n        this.resize(this._textureCanvas.width, this._textureCanvas.height, false);\n        // Draw applyFilter layers upon it\n        this._applyFilters.forEach((method, index) => {\n            if (!this._textureCtx || !this._textureCanvas || !this._originalImage)\n                return;\n            this._textureCtx.save();\n            method(this._textureCanvas, this._textureCtx, this._originalImage, this, this._applyFiltersData[index]);\n            this._textureCtx.restore();\n        });\n    }\n    /**\n     * Gets / sets the pre-filter method that will be called before\n     * the texture is rendered and will allow you to modify the texture\n     * image before rendering each tick.\n     * @param method\n     * @param data\n     * @return {*}\n     */\n    preFilter(method, data) {\n        if (!this._originalImage) {\n            return this;\n        }\n        if (!this._textureCtx || !this._textureCanvas) {\n            // Create a new canvas\n            this._textureCanvas = (0,_engine_core_IgeCanvas__WEBPACK_IMPORTED_MODULE_1__.newCanvas)();\n            this._textureCanvas.width = this._originalImage.width;\n            this._textureCanvas.height = this._originalImage.height;\n            const tmpCtx = this._textureCanvas.getContext(\"2d\");\n            if (!tmpCtx) {\n                throw new Error(\"Couldn't get texture canvas 2d context!\");\n            }\n            this._textureCtx = tmpCtx;\n            // Set smoothing mode\n            this._textureCtx.imageSmoothingEnabled = this._smoothing;\n        }\n        // Swap the current image for this new canvas\n        this.image = this._textureCanvas;\n        // Save filter in active preFilter list\n        this._preFilters[this._preFilters.length] = method;\n        this._preFiltersData[this._preFiltersData.length] = !data ? {} : data;\n        return this;\n    }\n    /**\n     * Applies a filter to the texture. The filter is a method that will\n     * take the canvas, context and originalImage parameters and then\n     * use context calls to alter / paint the context with the texture\n     * and any filter / adjustments that you want to apply.\n     * @param {Function} method\n     * @param {Object=} data\n     * @return {*}\n     */\n    applyFilter(method, data) {\n        if (!this._loaded) {\n            throw new Error(\"Cannot apply filter, the texture you are trying to apply the filter to has not yet loaded!\");\n        }\n        if (!this._originalImage) {\n            return this;\n        }\n        if (!this._textureCtx || !this._textureCanvas) {\n            // Create a new canvas\n            this._textureCanvas = (0,_engine_core_IgeCanvas__WEBPACK_IMPORTED_MODULE_1__.newCanvas)();\n            this._textureCanvas.width = this._originalImage.width;\n            this._textureCanvas.height = this._originalImage.height;\n            const tmpCtx = this._textureCanvas.getContext(\"2d\");\n            if (!tmpCtx) {\n                throw new Error(\"Couldn't get texture canvas 2d context!\");\n            }\n            this._textureCtx = tmpCtx;\n            // Draw the basic image\n            this._textureCtx.clearRect(0, 0, this._textureCanvas.width, this._textureCanvas.height);\n            this._textureCtx.drawImage(this._originalImage, 0, 0);\n            // Set smoothing mode\n            this._textureCtx.imageSmoothingEnabled = this._smoothing;\n        }\n        // Swap the current image for this new canvas\n        this.image = this._textureCanvas;\n        // Call the passed method\n        if (this._preFilters.length <= 0) {\n            this._textureCtx.save();\n            method(this._textureCanvas, this._textureCtx, this._originalImage, this, data);\n            this._textureCtx.restore();\n        }\n        // Save filter in active applyFiler list\n        this._applyFilters[this._applyFilters.length] = method;\n        this._applyFiltersData[this._applyFiltersData.length] = !data ? {} : data;\n        return this;\n    }\n    /**\n     * Retrieves pixel data from x,y texture coordinate (starts from top-left).\n     * Important: If the texture has a cross-domain url, the image host must allow\n     * cross-origin resource sharing or a security error will be thrown.\n     * Reference: http://blog.chromium.org/2011/07/using-cross-domain-images-in-webgl-and.html\n     * @param  {number} x\n     * @param  {number} y\n     * @return {Array} [r,g,b,a] Pixel data.\n     */\n    pixelData(x, y) {\n        if (!this._loaded) {\n            throw new Error(\"Cannot read pixel data, the texture you are trying to read data from has not yet loaded!\");\n        }\n        if (!this.image) {\n            return null;\n        }\n        // Check if the texture is already using a canvas\n        if (!this._textureCtx || !this._textureCanvas) {\n            // Create a new canvas\n            this._textureCanvas = (0,_engine_core_IgeCanvas__WEBPACK_IMPORTED_MODULE_1__.newCanvas)();\n            this._textureCanvas.width = this.image.width;\n            this._textureCanvas.height = this.image.height;\n            const tmpCtx = this._textureCanvas.getContext(\"2d\");\n            if (!tmpCtx) {\n                throw new Error(\"Couldn't get texture canvas 2d context!\");\n            }\n            this._textureCtx = tmpCtx;\n            // Set smoothing mode\n            this._textureCtx.imageSmoothingEnabled = this._smoothing;\n            // Draw the image to the canvas\n            this._textureCtx.drawImage(this.image, 0, 0);\n        }\n        const imageData = this._textureCtx.getImageData(x, y, 1, 1);\n        if (!imageData) {\n            return null;\n        }\n        return imageData.data;\n    }\n    /**\n     * Creates a clone of the texture.\n     * @return {IgeTexture} A new, distinct texture with the same attributes\n     * as the one being cloned.\n     */\n    clone() {\n        return this.textureFromCell(1);\n    }\n    /**\n     * Returns a string containing a code fragment that when\n     * evaluated will reproduce this object.\n     * @return {string}\n     */\n    stringify() {\n        let str = \"new \" + this.classId + \"('\" + this._url + \"')\";\n        // Every object has an ID, assign that first\n        // We've commented this because ids for textures are actually generated\n        // from their asset so will ALWAYS produce the same ID as long as the asset\n        // is the same path.\n        //str += \".id('\" + this.id() + \"')\";\n        // Now get all other properties\n        str += this._stringify();\n        return str;\n    }\n    /**\n     * Creates a new texture from a cell in the existing texture\n     * and returns the new texture.\n     * @param {number | string} indexOrId The cell index or id to use.\n     * @return {*}\n     */\n    textureFromCell(indexOrId) {\n        const tex = new IgeTexture();\n        if (this._loaded) {\n            this._textureFromCell(tex, indexOrId);\n        }\n        else {\n            // The texture has not yet loaded, return the new texture and set a listener to handle\n            // when this texture has loaded then we can assign the texture's image properly\n            this.on(\"loaded\", () => {\n                this._textureFromCell(tex, indexOrId);\n            });\n        }\n        return tex;\n    }\n    /**\n     * Called by textureFromCell() when the texture is ready\n     * to be processed. See textureFromCell() for description.\n     * @param {IgeTexture} tex The new texture to paint to.\n     * @param {number, String} indexOrId The cell index or id\n     * to use.\n     * @private\n     */\n    _textureFromCell(tex, indexOrId) {\n        if (!this._originalImage) {\n            throw new Error(\"Unable to create new texture from passed cell index because we don't have an _originalImage assigned to the IgeTexture!\");\n        }\n        let index;\n        if (typeof indexOrId === \"string\") {\n            // TODO: cellIdToIndex is part of the IgeSpriteSheet class\n            //   so this call is incorrect here, fix the whole process\n            index = this.cellIdToIndex(indexOrId);\n        }\n        else {\n            index = indexOrId;\n        }\n        if (!this._cells[index]) {\n            throw new Error(`Unable to create new texture from passed cell index (${indexOrId}) because the cell does not exist!`);\n        }\n        // Create a new IgeTexture, then draw the existing cell\n        // to its internal canvas\n        const cell = this._cells[index];\n        const canvas = (0,_engine_core_IgeCanvas__WEBPACK_IMPORTED_MODULE_1__.newCanvas)();\n        if (!canvas)\n            return;\n        const ctx = canvas.getContext(\"2d\");\n        if (!ctx) {\n            throw new Error(\"Unable to get 2d context from IgeTexture canvas\");\n        }\n        // Set smoothing mode\n        // TODO: Does this cause a costly context change? If so maybe we set a global value to keep\n        //    track of the value and evaluate first before changing?\n        ctx.imageSmoothingEnabled = this._smoothing;\n        canvas.width = cell[2];\n        canvas.height = cell[3];\n        // Draw the cell to the canvas\n        ctx.drawImage(this._originalImage, cell[0], cell[1], cell[2], cell[3], 0, 0, cell[2], cell[3]);\n        // Set the new texture's image to the canvas\n        // TODO: We need to figure out how to create a uniform interface for using either\n        //\t\tan image or a canvas source for texture image data\n        tex._setImage(canvas);\n        tex._loaded = true;\n        // Fire the loaded event\n        setTimeout(() => {\n            tex.emit(\"loaded\");\n        }, 1);\n    }\n    /**\n     * Returns the cell index that the passed cell id corresponds\n     * to.\n     * @param {string} id\n     * @return {number} The cell index that the cell id corresponds\n     * to or -1 if a corresponding index could not be found.\n     */\n    cellIdToIndex(id) {\n        const cells = this._cells;\n        for (let i = 1; i < cells.length; i++) {\n            if (cells[i][4] === id) {\n                // Found the cell id so return the index\n                return i;\n            }\n        }\n        return -1;\n    }\n    _stringify() {\n        return \"\";\n    }\n    /**\n     * Destroys the item.\n     */\n    destroy() {\n        delete this._eventListeners;\n        // Remove us from the image store reference array\n        if (this.image && this.image._igeTextures) {\n            (0,_engine_utils_arrays__WEBPACK_IMPORTED_MODULE_4__.arrPull)(this.image._igeTextures, this);\n        }\n        // Remove the texture from the texture store\n        const id = this.id();\n        if (id) {\n            _engine_instance__WEBPACK_IMPORTED_MODULE_3__.ige.textures.remove(id);\n        }\n        delete this.image;\n        delete this.script;\n        delete this._textureCanvas;\n        delete this._textureCtx;\n        this._destroyed = true;\n        return this;\n    }\n}\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/core/IgeTexture.ts?");

/***/ }),

/***/ "./src/engine/core/IgeWebGpuRenderer.ts":
/*!**********************************************!*\
  !*** ./src/engine/core/IgeWebGpuRenderer.ts ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   IgeWebGpuRenderer: () => (/* binding */ IgeWebGpuRenderer)\n/* harmony export */ });\n/* harmony import */ var _engine_core_IgeBaseRenderer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @/engine/core/IgeBaseRenderer */ \"./src/engine/core/IgeBaseRenderer.ts\");\n/* harmony import */ var _engine_instance__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @/engine/instance */ \"./src/engine/instance.ts\");\n/* harmony import */ var _engine_shaders_2d__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @/engine/shaders/2d */ \"./src/engine/shaders/2d.ts\");\n/* harmony import */ var _engine_utils_buffers__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @/engine/utils/buffers */ \"./src/engine/utils/buffers.ts\");\n/* harmony import */ var _engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @/engine/utils/clientServer */ \"./src/engine/utils/clientServer.ts\");\n/* harmony import */ var gl_matrix__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! gl-matrix */ \"./node_modules/gl-matrix/esm/mat4.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\n\nclass IgeWebGpuRenderer extends _engine_core_IgeBaseRenderer__WEBPACK_IMPORTED_MODULE_0__.IgeBaseRenderer {\n    constructor() {\n        super();\n        this.classId = \"IgeWebGpuRenderer\";\n        this._adapter = null;\n        this._device = null;\n        this._textureFormat = null;\n        this._rectVertexBuffer = null;\n        this._rectIndexBuffer = null;\n        this._uniformBuffer = null;\n        this._uniformsBindGroup = null;\n        this._textureBindGroup = null;\n        this._uniformValues = null;\n        this._pipeline = null;\n        this._projectionViewMatrixValue = null;\n        this._colorValue = null;\n        this._resolutionValue = null;\n        this._renderPassDescriptor = null;\n        if (!navigator.gpu) {\n            this.logError(\"Cannot use WebGPU renderer because `navigator.gpu` did not return a value\");\n        }\n    }\n    /**\n     * Creates a front-buffer or \"drawing surface\" for the renderer.\n     *\n     * @param {Boolean} autoSize Determines if the canvas will auto-resize\n     * when the browser window changes dimensions. If true the canvas will\n     * automatically fill the window when it is resized.\n     *\n     * @param {Boolean=} dontScale If set to true, IGE will ignore device\n     * pixel ratios when setting the width and height of the canvas and will\n     * therefore not take into account \"retina\", high-definition displays or\n     * those whose pixel ratio is different from 1 to 1.\n     */\n    createFrontBuffer(autoSize = true, dontScale = false) {\n        if (!_engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_4__.isClient) {\n            return;\n        }\n        if (this._canvasElement) {\n            return;\n        }\n        this._createdFrontBuffer = true;\n        this._pixelRatioScaling = !dontScale;\n        // Create a new canvas element to use as the\n        // rendering front-buffer\n        const tempCanvas = document.createElement(\"canvas\");\n        this.canvasElement(tempCanvas, autoSize);\n        document.body.appendChild(tempCanvas);\n    }\n    /**\n     * Gets / sets the canvas element that will be used as the front-buffer.\n     * @param elem The canvas element.\n     * @param autoSize If set to true, the engine will automatically size\n     * the canvas to the width and height of the window upon window resize.\n     */\n    canvasElement(elem, autoSize = true) {\n        if (_engine_utils_clientServer__WEBPACK_IMPORTED_MODULE_4__.isServer)\n            return;\n        if (elem === undefined) {\n            // Return current value\n            return this._canvasElement;\n        }\n        this._canvasElement = elem;\n        this._canvasElement.className = \"igeRendererOutput\";\n        this._updateDevicePixelRatio();\n        this.log(`Device pixel ratio is ${this._devicePixelRatio}`);\n        this._autoSize = autoSize;\n        window.addEventListener(\"resize\", this._resizeEvent);\n        this._resizeEvent();\n        _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine.headless(false);\n        // Ask the input component to set up any listeners it has\n        _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.input.setupListeners(this._canvasElement);\n    }\n    _createRectVertexBuffer(device, size = 32) {\n        return device.createBuffer({\n            label: \"rect vertex buffer\",\n            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,\n            size\n        });\n    }\n    _createRectIndexBuffer(device, size = 24) {\n        return device.createBuffer({\n            label: \"rect index buffer\",\n            usage: GPUBufferUsage.INDEX | GPUBufferUsage.COPY_DST,\n            size\n        });\n    }\n    _createTextureFromImage(device, image) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const texture = device.createTexture({\n                size: { width: image.width, height: image.height },\n                format: \"rgba8unorm\",\n                usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT\n            });\n            const data = yield createImageBitmap(image);\n            device.queue.copyExternalImageToTexture({ source: data }, { texture: texture }, { width: image.width, height: image.height });\n            const sampler = device.createSampler({\n                magFilter: \"linear\",\n                minFilter: \"linear\"\n            });\n            return [texture, sampler];\n        });\n    }\n    _createTextureFromURL(device, url) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const imagePromise = new Promise((resolve, reject) => {\n                const image = new Image();\n                image.src = url;\n                image.onload = () => resolve(image);\n                image.onerror = () => {\n                    console.error(`Failed to load image ${url}`);\n                    reject();\n                };\n            });\n            const image = yield imagePromise;\n            return this._createTextureFromImage(device, image);\n        });\n    }\n    _getAdaptor() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._adapter)\n                throw new Error(\"Already have an adapter\");\n            this._adapter = yield navigator.gpu.requestAdapter();\n            if (!this._adapter) {\n                this.logError(\"Cannot start because adapter not returned from `navigator.gpu.requestAdapter()`\");\n            }\n        });\n    }\n    _getDevice() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._device)\n                throw new Error(\"Already have a device\");\n            if (!this._adapter) {\n                this.logError(\"Cannot get device because no adaptor is present\");\n                return;\n            }\n            this._device = yield this._adapter.requestDevice();\n            if (!this._device) {\n                this.logError(\"Cannot start because device not returned from `adapter.requestDevice()`\");\n            }\n            this._device.lost.then(() => {\n                this.logError(\"GPU device has been lost\");\n                this._device = null;\n                return null;\n            });\n        });\n    }\n    _getContext() {\n        if (this._canvasContext)\n            throw new Error(\"Already have a context\");\n        if (!this._canvasElement) {\n            throw new Error(\"No canvas element was found when trying to get context\");\n        }\n        if (!this._adapter)\n            return;\n        if (!this._device)\n            return;\n        this._canvasContext = this._canvasElement.getContext(\"webgpu\");\n        // If we didn't get a context, fail completely\n        if (!this._canvasContext) {\n            this.logError(\"Could not get canvas context, renderer unable to start. This is a critical error that means the engine cannot start.\");\n            return;\n        }\n        this._textureFormat = navigator.gpu.getPreferredCanvasFormat();\n        this._canvasContext.configure({\n            device: this._device,\n            format: this._textureFormat,\n            alphaMode: \"opaque\"\n        });\n    }\n    renderSceneGraph(engine, viewports) {\n        const ctx = this._canvasContext;\n        if (!ctx)\n            return false;\n        let ts;\n        let td;\n        if (viewports) {\n            //ctx.save();\n            //ctx.translate(bounds.x2, bounds.y2);\n            //ctx.scale(this._globalScale.x, this._globalScale.y);\n            let arrCount = viewports.length;\n            // Loop our viewports and call their tick methods\n            if (_engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.config.debug._timing) {\n                while (arrCount--) {\n                    //ctx.save();\n                    ts = new Date().getTime();\n                    //arr[arrCount].tick(ctx);\n                    td = new Date().getTime() - ts;\n                    if (viewports[arrCount]) {\n                        if (!_engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._timeSpentInTick[viewports[arrCount].id()]) {\n                            _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._timeSpentInTick[viewports[arrCount].id()] = 0;\n                        }\n                        if (!_engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._timeSpentLastTick[viewports[arrCount].id()]) {\n                            _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._timeSpentLastTick[viewports[arrCount].id()] = {};\n                        }\n                        _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._timeSpentInTick[viewports[arrCount].id()] += td;\n                        _engine_instance__WEBPACK_IMPORTED_MODULE_1__.ige.engine._timeSpentLastTick[viewports[arrCount].id()].ms = td;\n                    }\n                    //ctx.restore();\n                }\n            }\n            else {\n                while (arrCount--) {\n                    //ctx.save();\n                    //arr[arrCount].tick(ctx);\n                    //ctx.restore();\n                    const entity = viewports[arrCount];\n                }\n            }\n            //ctx.restore();\n        }\n        this._webgpuRender(viewports);\n        return super.renderSceneGraph(engine, viewports);\n    }\n    _createRect(width, height) {\n        const indexData = new Uint32Array([\n            0, 1, 2,\n            2, 1, 3\n        ]);\n        const vertexData = [\n            0, 0,\n            width, 0,\n            0, height,\n            width, height\n        ];\n        const colorData = [\n            1.0, 1.0, 1.0, 1.0, // r g b a\n            1.0, 1.0, 1.0, 1.0, // r g b a\n            1.0, 1.0, 1.0, 1.0, // r g b a\n            1.0, 1.0, 1.0, 1.0 // r g b a\n        ];\n        // TODO: Need to flip the texture upside down as we are flipping the y in\n        // the shader to accommodate painting coords being flipped in canvas space\n        // maybe we should do that before sending it to the shader?\n        const textureCoordsData = [\n            0.0, 0.0, // u, v\n            1.0, 0.0,\n            0.0, 1.0,\n            1.0, 1.0\n        ];\n        return {\n            indexData,\n            vertexData: new Float32Array((0,_engine_utils_buffers__WEBPACK_IMPORTED_MODULE_3__.packArraysByFormat)([0, 0, 1, 1, 1, 1, 2, 2], vertexData, colorData, textureCoordsData))\n        };\n    }\n    _setup() {\n        const _super = Object.create(null, {\n            _setup: { get: () => super._setup }\n        });\n        return __awaiter(this, void 0, void 0, function* () {\n            yield _super._setup.call(this);\n            this.createFrontBuffer();\n            yield this._getAdaptor();\n            yield this._getDevice();\n            this._updateDevicePixelRatio();\n            this._getContext();\n            this._addEventListeners();\n            this._resizeEvent();\n            if (!this._device)\n                return;\n            if (!this._textureFormat)\n                return;\n            if (!this._canvasElement)\n                return;\n            if (!this._canvasContext)\n                return;\n            const [testTexture, textureSampler] = yield this._createTextureFromURL(this._device, \"./uv_test.png\");\n            const uniformsBindGroupLayout = this._device.createBindGroupLayout({\n                entries: [\n                    {\n                        binding: 0,\n                        visibility: GPUShaderStage.VERTEX,\n                        buffer: {\n                            type: \"uniform\"\n                            //hasDynamicOffset: false,\n                            //minBindingSize: uniformBufferRangeData.byteLength\n                        }\n                    }\n                ]\n            });\n            const textureBindGroupLayout = this._device.createBindGroupLayout({\n                entries: [\n                    {\n                        binding: 0,\n                        visibility: GPUShaderStage.FRAGMENT,\n                        sampler: {}\n                    },\n                    {\n                        binding: 1,\n                        visibility: GPUShaderStage.FRAGMENT,\n                        texture: {}\n                    }\n                ]\n            });\n            const pipelineLayout = this._device.createPipelineLayout({\n                bindGroupLayouts: [\n                    uniformsBindGroupLayout,\n                    textureBindGroupLayout\n                ]\n            });\n            this._pipeline = (0,_engine_shaders_2d__WEBPACK_IMPORTED_MODULE_2__.getPipeline)(this._device, this._textureFormat, pipelineLayout);\n            // color, resolution, padding\n            const uniformBufferRangeData = (0,_engine_utils_buffers__WEBPACK_IMPORTED_MODULE_3__.bufferRangeData)(Float32Array.BYTES_PER_ELEMENT, // Using float32s (32 bits each, 4 bytes)\n            (4 * 4), // Mat4 x 4 floats\n            4, // 4 floats\n            2 // 2 floats\n            );\n            // Create a buffer data array\n            this._uniformValues = new Float32Array(uniformBufferRangeData.length);\n            this._uniformBuffer = this._device.createBuffer({\n                label: \"uniforms buffer\",\n                size: (0,_engine_utils_buffers__WEBPACK_IMPORTED_MODULE_3__.getMultipleOf)(16, this._uniformValues.byteLength),\n                usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST\n            });\n            // Create a reference to a sub-space inside the buffer (start position, end position)\n            this._projectionViewMatrixValue = this._uniformValues.subarray(uniformBufferRangeData.ranges[0][0], uniformBufferRangeData.ranges[0][1]);\n            this._colorValue = this._uniformValues.subarray(uniformBufferRangeData.ranges[1][0], uniformBufferRangeData.ranges[1][1]);\n            this._resolutionValue = this._uniformValues.subarray(uniformBufferRangeData.ranges[2][0], uniformBufferRangeData.ranges[2][1]);\n            // The color will not change so let's set it once at init time\n            this._colorValue.set([Math.random(), Math.random(), Math.random(), 1]);\n            this._rectVertexBuffer = this._createRectVertexBuffer(this._device, 128);\n            this._rectIndexBuffer = this._createRectIndexBuffer(this._device);\n            this._uniformsBindGroup = this._device.createBindGroup({\n                label: \"bind group for uniforms\",\n                layout: this._pipeline.getBindGroupLayout(0),\n                entries: [\n                    {\n                        binding: 0,\n                        resource: {\n                            buffer: this._uniformBuffer\n                        }\n                    }\n                ]\n            });\n            this._textureBindGroup = this._device.createBindGroup({\n                label: \"bind group for texture\",\n                layout: this._pipeline.getBindGroupLayout(1),\n                entries: [\n                    {\n                        binding: 0,\n                        resource: textureSampler\n                    },\n                    {\n                        binding: 1,\n                        resource: testTexture.createView()\n                    }\n                ]\n            });\n            this.isReady(true);\n        });\n    }\n    _webgpuRender(arr) {\n        if (!this._device)\n            return;\n        if (!this._textureFormat)\n            return;\n        if (!this._canvasElement)\n            return;\n        if (!this._canvasContext)\n            return;\n        if (!this._rectVertexBuffer)\n            return;\n        if (!this._rectIndexBuffer)\n            return;\n        if (!this._uniformBuffer)\n            return;\n        if (!this._pipeline)\n            return;\n        if (!this._uniformValues)\n            return;\n        if (!this._projectionViewMatrixValue)\n            return;\n        if (!this._resolutionValue)\n            return;\n        const viewport = arr[0];\n        if (!viewport)\n            return;\n        // Get the current texture from the canvas context and\n        // set it as the texture to render to.\n        this._renderPassDescriptor = {\n            label: \"default renderPass\",\n            colorAttachments: [\n                {\n                    view: this._canvasContext.getCurrentTexture().createView(),\n                    loadOp: \"clear\",\n                    storeOp: \"store\"\n                }\n            ]\n        };\n        const encoder = this._device.createCommandEncoder();\n        const pass = encoder.beginRenderPass(this._renderPassDescriptor);\n        pass.setPipeline(this._pipeline);\n        pass.setVertexBuffer(0, this._rectVertexBuffer);\n        pass.setIndexBuffer(this._rectIndexBuffer, \"uint32\");\n        pass.setBindGroup(0, this._uniformsBindGroup);\n        pass.setBindGroup(1, this._textureBindGroup);\n        // TEMP CODE UNTIL WE FIGURE OUT BEST WAY TO HANDLE THIS WITH CAMERA AND VIEWPORT\n        const viewMatrix = gl_matrix__WEBPACK_IMPORTED_MODULE_5__.lookAt(gl_matrix__WEBPACK_IMPORTED_MODULE_5__.create(), [0, 0, 1], [0, 0, 0], [0, 1, 0]);\n        const projectionViewMatrix = gl_matrix__WEBPACK_IMPORTED_MODULE_5__.create();\n        gl_matrix__WEBPACK_IMPORTED_MODULE_5__.multiply(projectionViewMatrix, projectionViewMatrix, viewMatrix);\n        // Set the uniform values in our JavaScript side Float32Array\n        this._projectionViewMatrixValue.set(projectionViewMatrix);\n        this._resolutionValue.set([this._canvasElement.width, this._canvasElement.height]);\n        // upload the uniform values to the uniform buffer\n        this._device.queue.writeBuffer(this._uniformBuffer, 0, this._uniformValues);\n        for (let i = 0; i < 100; i++) {\n            // The zero here is the position to copy the vertex data into the rectVertexBuffer\n            const { vertexData, indexData } = this._createRect(Math.random() * 100, Math.random() * 100);\n            this._device.queue.writeBuffer(this._rectVertexBuffer, 0, vertexData);\n            this._device.queue.writeBuffer(this._rectIndexBuffer, 0, indexData);\n            pass.drawIndexed(indexData.length);\n        }\n        pass.end();\n        const commandBuffer = encoder.finish();\n        this._device.queue.submit([commandBuffer]);\n    }\n    /**\n     * Clears the entire canvas.\n     */\n    clear() {\n        if (!(this._canvasElement && this._canvasContext))\n            return;\n        //this._canvasContext.clearRect(0, 0, this._canvasElement.width, this._canvasElement.height);\n    }\n}\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/core/IgeWebGpuRenderer.ts?");

/***/ }),

/***/ "./src/engine/shaders/2d.ts":
/*!**********************************!*\
  !*** ./src/engine/shaders/2d.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getPipeline: () => (/* binding */ getPipeline),\n/* harmony export */   getShaderModule: () => (/* binding */ getShaderModule),\n/* harmony export */   vertexDataFormat: () => (/* binding */ vertexDataFormat)\n/* harmony export */ });\n/* harmony import */ var _engine_utils_buffers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @/engine/utils/buffers */ \"./src/engine/utils/buffers.ts\");\n\nconst shaderSource = `\nstruct Uniforms {\n  projectionViewMatrix: mat4x4f,\n  color: vec4f,\n  resolution: vec2f,\n};\n\nstruct Vertex {\n  @location(0) position: vec2f,  // xy\n  @location(1) color: vec4f,  // rgba\n  @location(2) texCoords: vec2f, // uv\n};\n\nstruct Instance {\n  @builtin(instance_index) instance: u32,\n}\n\nstruct VertexShaderResult {\n  @builtin(position) position: vec4f,\n  @location(0) color: vec4f,\n  @location(1) texCoords: vec2f,\n};\n\n@group(0) @binding(0) var<uniform> uni: Uniforms;\n@group(1) @binding(0) var texSampler: sampler;\n@group(1) @binding(1) var texture: texture_2d<f32>;\n\n@vertex fn vs(vert: Vertex, @builtin(instance_index) instance: u32) -> VertexShaderResult {\n  var vsOut: VertexShaderResult;\n\n  //let i = f32(instance);\n  //let position = vert.position;\n\n  // convert the position from pixels to a 0.0 to 1.0 value\n  //let zeroToOne = position / uni.resolution;\n\n  // convert from 0 <-> 1 to 0 <-> 2\n  //let zeroToTwo = zeroToOne * 2.0;\n\n  // covert from 0 <-> 2 to -1 <-> +1 (clip space)\n  //let flippedClipSpace = zeroToTwo - 1.0;\n\n  // flip Y\n  //let clipSpace = flippedClipSpace * vec2f(1, -1);\n\n  //vsOut.position = vec4f(clipSpace, 0.0, 1.0);\n  \n  vsOut.position = uni.projectionViewMatrix * vec4f(vert.position, 0, 1);\n  vsOut.color = vert.color;\n  vsOut.texCoords = vert.texCoords;\n\n  return vsOut;\n}\n\n@fragment fn fs(fragData: VertexShaderResult) -> @location(0) vec4f {\n  var textureColor = textureSample(texture, texSampler, fragData.texCoords);\n  return fragData.color * textureColor;\n}\n`;\n// x, y, r, g, b, a, u, v\nconst vertexDataFormat = [0, 0, 1, 1, 1, 1, 2, 2];\nconst getShaderModule = (device) => {\n    return device.createShaderModule({\n        code: shaderSource\n    });\n};\nconst getPipeline = (device, textureFormat, pipelineLayout) => {\n    const shaderModule = getShaderModule(device);\n    const vertexBufferLayout = (0,_engine_utils_buffers__WEBPACK_IMPORTED_MODULE_0__.vertexBufferLayoutByFormat)(vertexDataFormat);\n    const pipelineData = {\n        label: \"default render pipeline\",\n        layout: pipelineLayout,\n        vertex: {\n            module: shaderModule,\n            entryPoint: \"vs\",\n            buffers: [\n                vertexBufferLayout\n            ]\n        },\n        fragment: {\n            module: shaderModule,\n            entryPoint: \"fs\",\n            targets: [{\n                    format: textureFormat,\n                    blend: {\n                        color: {\n                            srcFactor: \"one\",\n                            dstFactor: \"one-minus-src-alpha\",\n                            operation: \"add\"\n                        },\n                        alpha: {\n                            srcFactor: \"one\",\n                            dstFactor: \"one-minus-src-alpha\",\n                            operation: \"add\"\n                        }\n                    }\n                }]\n        },\n        primitive: {\n            topology: \"triangle-list\" // type of primitive to render\n        }\n    };\n    console.log(pipelineData);\n    return device.createRenderPipeline(pipelineData);\n};\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/shaders/2d.ts?");

/***/ }),

/***/ "./src/engine/utils/buffers.ts":
/*!*************************************!*\
  !*** ./src/engine/utils/buffers.ts ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   bufferRangeData: () => (/* binding */ bufferRangeData),\n/* harmony export */   createTextureFromImage: () => (/* binding */ createTextureFromImage),\n/* harmony export */   getMultipleOf: () => (/* binding */ getMultipleOf),\n/* harmony export */   packArraysByFormat: () => (/* binding */ packArraysByFormat),\n/* harmony export */   vertexBufferLayoutByFormat: () => (/* binding */ vertexBufferLayoutByFormat)\n/* harmony export */ });\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nfunction packArraysByFormat(format, ...dataArgs) {\n    // Format is in the structure of array indexes of the passed\n    // dataArgs e.g. [x, y, r, g, b, a, u, v] would be expressed\n    // by a call to packBuffers(\n    // \t [0, 0, 1, 1, 1, 1, 2, 2], vertexData, colorData, uvData\n    // );\n    // So take two from vertexData, four from colorData then two from uvData\n    // then start again until all data has been depleted\n    const indexTracking = new Array(dataArgs.length).fill(0);\n    const data = [];\n    while (dataArgs[0][indexTracking[0]] !== undefined) {\n        const row = format.map((dataArgIndex) => {\n            const dataValue = dataArgs[dataArgIndex][indexTracking[dataArgIndex]];\n            indexTracking[dataArgIndex]++;\n            return dataValue;\n        });\n        data.push(...row);\n    }\n    return data;\n}\nfunction vertexBufferLayoutByFormat(format) {\n    const shaderLocationRanges = [];\n    format.forEach((shaderLocationIndex, formatIndex) => {\n        if (shaderLocationRanges[shaderLocationIndex]) {\n            shaderLocationRanges[shaderLocationIndex].count++;\n        }\n        else {\n            shaderLocationRanges[shaderLocationIndex] = shaderLocationRanges[shaderLocationIndex] || {\n                startIndex: formatIndex,\n                count: 1\n            };\n        }\n    });\n    /**\n     * Generate attribute entries like:\n     * [\n     * \t{\n     * \t\tshaderLocation: 0,\n     * \t\toffset: 0,\n     * \t\tformat: \"float32x2\" // 2 floats\n     * \t},\n     * \t{\n     * \t\tshaderLocation: 1,\n     * \t\toffset: 2 * Float32Array.BYTES_PER_ELEMENT,\n     * \t\tformat: \"float32x4\" // 4 floats\n     * \t},\n     * \t{\n     * \t\tshaderLocation: 2,\n     * \t\toffset: 6 * Float32Array.BYTES_PER_ELEMENT,\n     * \t\tformat: \"float32x2\" // 2 floats\n     * \t}\n     * ]\n     */\n    const attributes = shaderLocationRanges.reduce((attrArr, { startIndex, count }, locationIndex) => {\n        const previousCount = locationIndex > 0 ? shaderLocationRanges[locationIndex - 1].count : 0;\n        const previousStartIndex = locationIndex > 0 ? shaderLocationRanges[locationIndex - 1].startIndex : 0;\n        const attr = {\n            shaderLocation: locationIndex,\n            offset: (previousStartIndex + previousCount) * Float32Array.BYTES_PER_ELEMENT,\n            format: `float32x${count}` // 2 floats\n        };\n        attrArr.push(attr);\n        return attrArr;\n    }, []);\n    const layout = {\n        arrayStride: format.length * Float32Array.BYTES_PER_ELEMENT, // floats length * 4 bytes per float\n        attributes,\n        stepMode: \"vertex\"\n    };\n    return layout;\n}\nfunction createTextureFromImage(device, image) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const texture = device.createTexture({\n            size: { width: image.width, height: image.height },\n            format: \"rgba8unorm\",\n            usage: GPUTextureUsage.COPY_DST | GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT\n        });\n        const data = yield createImageBitmap(image);\n        device.queue.copyExternalImageToTexture({ source: data }, { texture: texture }, { width: image.width, height: image.height });\n        const sampler = device.createSampler({\n            magFilter: \"linear\",\n            minFilter: \"linear\"\n        });\n        return [texture, sampler];\n    });\n}\nconst bufferRangeData = (bytesPerItem, ...numberOfItems) => {\n    const ranges = [];\n    let length = 0;\n    numberOfItems.forEach((item, itemIndex) => {\n        ranges[itemIndex] = [length, length + item];\n        length += item;\n    });\n    return { byteLength: length * bytesPerItem, length, ranges };\n};\nconst getMultipleOf = (targetMultiple, currentVal) => {\n    const multiplier = Math.ceil(currentVal / targetMultiple);\n    return targetMultiple * multiplier;\n};\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/engine/utils/buffers.ts?");

/***/ }),

/***/ "./src/examples/webGpuRenderer/client.ts":
/*!***********************************************!*\
  !*** ./src/examples/webGpuRenderer/client.ts ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Client: () => (/* binding */ Client)\n/* harmony export */ });\n/* harmony import */ var _engine_core_IgeBaseClass__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @/engine/core/IgeBaseClass */ \"./src/engine/core/IgeBaseClass.ts\");\n/* harmony import */ var _engine_core_IgeBaseScene__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @/engine/core/IgeBaseScene */ \"./src/engine/core/IgeBaseScene.ts\");\n/* harmony import */ var _engine_core_IgeTexture__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @/engine/core/IgeTexture */ \"./src/engine/core/IgeTexture.ts\");\n/* harmony import */ var _engine_core_IgeWebGpuRenderer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @/engine/core/IgeWebGpuRenderer */ \"./src/engine/core/IgeWebGpuRenderer.ts\");\n/* harmony import */ var _engine_instance__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @/engine/instance */ \"./src/engine/instance.ts\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n// @ts-ignore\n\n\n\n\n\n// @ts-ignore\nwindow.ige = _engine_instance__WEBPACK_IMPORTED_MODULE_4__.ige;\nclass Client extends _engine_core_IgeBaseClass__WEBPACK_IMPORTED_MODULE_0__.IgeBaseClass {\n    constructor() {\n        super();\n        this.classId = \"Client\";\n        void this.init();\n    }\n    init() {\n        return __awaiter(this, void 0, void 0, function* () {\n            // Load the game textures\n            new _engine_core_IgeTexture__WEBPACK_IMPORTED_MODULE_2__.IgeTexture(\"fairy\", \"../../assets/textures/sprites/fairy.png\");\n            // Wait for our textures to load before continuing\n            yield _engine_instance__WEBPACK_IMPORTED_MODULE_4__.ige.textures.whenLoaded();\n            // Create the HTML canvas\n            const renderer = new _engine_core_IgeWebGpuRenderer__WEBPACK_IMPORTED_MODULE_3__.IgeWebGpuRenderer();\n            _engine_instance__WEBPACK_IMPORTED_MODULE_4__.ige.engine.renderer(renderer);\n            // Start the engine\n            yield _engine_instance__WEBPACK_IMPORTED_MODULE_4__.ige.engine.start();\n            void _engine_instance__WEBPACK_IMPORTED_MODULE_4__.ige.engine.addGraph(_engine_core_IgeBaseScene__WEBPACK_IMPORTED_MODULE_1__.IgeBaseScene);\n        });\n    }\n}\n\n\n//# sourceURL=webpack://@irrelon/ige/./src/examples/webGpuRenderer/client.ts?");

/***/ })

}]);